{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97daea22-c3de-4e4c-b415-b13f2cec648a",
   "metadata": {},
   "source": [
    "# Overview of the datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b118f80-5e9c-4a81-8a6e-34d8bc0441e7",
   "metadata": {},
   "source": [
    "This notebook handles download of a pre-made datacube, and some visualisations to help understanding of it and check its health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2caf0-3149-4080-a480-97178a17ed56",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea711e-8ba0-43a6-8ed1-e9394062845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask as da\n",
    "import zarr\n",
    "import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from chaosmagpy.plot_utils import nio_colormap\n",
    "\n",
    "try:\n",
    "    from src.data.proc_env import INT_FILE_PATHS\n",
    "    from src.env import REFRAD, TMPDIR\n",
    "except ImportError:\n",
    "    print(\"Failed to import src...\")\n",
    "    TMPDIR = os.getcwd()\n",
    "    INT_FILE_PATHS = {\"A\": os.path.join(TMPDIR, \"SwA_20140501-20190501_proc1.nc\")}\n",
    "    REFRAD = 6371200\n",
    "    print(\"Using instead for cube download and scratch space:\", TMPDIR)\n",
    "if not os.path.exists(TMPDIR):\n",
    "    print(\"Can't find scratch space:\", TMPDIR)\n",
    "    TMPDIR = os.getcwd()\n",
    "    print(\"Using instead:\", TMPDIR)\n",
    "\n",
    "xr.set_options(\n",
    "    display_expand_attrs=False,\n",
    "    display_expand_data_vars=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec07faa-ff4d-4b71-956f-f002ad473745",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Using temporary working directory:\",\n",
    "    TMPDIR,\n",
    "    \"Is this a good location for data I/O? Configure this path in the file: geomagnetic_datacubes_dev/config.ini\",\n",
    "    \"(or manually enter new paths above if not using the geomagcubes environment)\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a44d5-4405-4b8e-b992-c9ac6b00c6d2",
   "metadata": {},
   "source": [
    "## Load/prepare datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a792f0-2369-458c-9e75-340d43124b00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download pre-made datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1512212-9a15-4850-a93f-5d31753f3b60",
   "metadata": {},
   "source": [
    "This part to be refactored into the datacube generation pipeline, when a permanent link is made available.\n",
    "\n",
    "Download the file if we don't already have it available here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38679d2-f804-480b-a6b4-6ea871b97eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location at which the data will be located\n",
    "fpath = INT_FILE_PATHS[\"A\"]\n",
    "path, fname = os.path.split(fpath)\n",
    "path, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c532c-ac79-4439-8f7a-60bfaa6980f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete it if you want to redownload it\n",
    "# os.remove(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c755792-e4eb-4b9a-933c-f135e4d1d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fpath):\n",
    "    # Skip the download if we already have the file\n",
    "    print(\"Already found file:\", fpath, sep=\"\\n\")\n",
    "    pass\n",
    "else:\n",
    "    pooch.retrieve(\n",
    "        url=\"https://nc.smithara.net/index.php/s/H5R923DsbtirfJy/download\",\n",
    "        known_hash=\"1b7a8cbc0cb1657f8d4444ae7f6bbab91841318e1a172fa1f8a487b9d9492912\",\n",
    "        path=path, fname=fname,\n",
    "        progressbar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612815ad-5154-4be1-a5fb-6e731987b6f0",
   "metadata": {},
   "source": [
    "### Make a copy of the input datacube as a Zarr store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681bf86-dcb7-48a1-96fc-c7a05a52a1e7",
   "metadata": {},
   "source": [
    "We want to make sure we don't accidentally modify the input dataset, so let's work on a copy. There are also some opportunities with xarray and dask and the zarr format to increase performance by dividing into chunks / rearranging the data in different ways - the input data format is not necessarily what we want to use for computation. So here we convert the data to the [Zarr](https://zarr.readthedocs.io) format\n",
    "\n",
    "(could work with the .nc file just the same; not sure yet what the advantages of zarr are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261ae4d-031e-410c-97e6-9b734320c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = INT_FILE_PATHS[\"A\"]\n",
    "zarr_store = os.path.join(TMPDIR, \"datacube_test.zarr\")\n",
    "print(\"Input file:\", file_in, \"Copying to:\", zarr_store, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd7ab8-bc34-4117-a309-30071eb2e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zarr_store):\n",
    "    print(\"Already found zarr:\", zarr_store, sep=\"\\n\")\n",
    "    pass\n",
    "else:\n",
    "    with xr.open_dataset(file_in) as ds:\n",
    "        ds.to_zarr(zarr_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b8d40-3e66-449d-934c-6aae16c653c9",
   "metadata": {},
   "source": [
    "## Diagnostics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be71365-102a-4886-8007-2891a070ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    zarr_store, engine=\"zarr\",\n",
    "    chunks=\"auto\"\n",
    ")\n",
    "# Remove the sources for now (to be fixed later)\n",
    "ds.attrs.pop(\"Sources\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a93f86-1f3b-4f80-993e-dc41df684665",
   "metadata": {},
   "source": [
    "Assuming input 1Hz data, this is how much the data has been decimated by  \n",
    "(i.e. it is 10s sampling, with a bit more lost due to quality Flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4541ee-c705-4488-beb0-86cc7a5f9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_ns = float(ds[\"Timestamp\"].isel(Timestamp=-1) - ds[\"Timestamp\"].isel(Timestamp=0))\n",
    "print(\"Fraction of input data:\", len(ds[\"Timestamp\"]) / (timedelta_ns/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa5c51-6b2b-44a0-b288-b95d95fc989b",
   "metadata": {},
   "source": [
    "### Spatial variation of magnetic field data, and data-model residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c9f52-5bcd-404c-87d9-821ceb9af173",
   "metadata": {},
   "source": [
    "Do some tricks to generate manageable summary images...\n",
    "\n",
    "First downsample again so we don't needlessly work with all the data just for these visualisations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f466810-7d28-4e24-aba0-c5b39cc7b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset downsampled by 1/30 (i.e. 5-minute sampling)\n",
    "_ds = ds.isel(Timestamp=slice(0, -1, 30))\n",
    "# Generate residuals to plot\n",
    "_ds[\"B_NEC_res_CHAOS-full\"] = (\n",
    "    _ds[\"B_NEC\"]\n",
    "    - _ds[\"B_NEC_CHAOS-MCO\"]\n",
    "    - _ds[\"B_NEC_CHAOS-MMA\"]\n",
    "    - _ds[\"B_NEC_CHAOS-Static_n16plus\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb222f-d21c-4937-b207-91fddb7c8d06",
   "metadata": {},
   "source": [
    "These next plots use `hvplot` (using `holoviews`) underneath to generate interactive `bokeh` plots - this is quite tricky to work with so better left alone until you have mastered `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9645bfc-298b-4380-9665-f70bcf5d4cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_NEC_var(_ds=_ds, var=\"B_NEC\", qdmlt=False, **kwargs):\n",
    "    if qdmlt:\n",
    "        x, y = \"MLT\", \"QDLat\"\n",
    "    else:\n",
    "        x, y = \"Longitude\", \"Latitude\"\n",
    "    return (\n",
    "        _ds.drop(\"Timestamp\")\n",
    "        .hvplot.scatter(\n",
    "            x=x, y=y, c=var,\n",
    "            by=\"NEC\", subplots=True,\n",
    "            rasterize=True,\n",
    "            colorbar=True,\n",
    "            hover=True,\n",
    "            width=300, height=200,\n",
    "            **kwargs\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"B_NEC: magnetic field measurements\")\n",
    "plot_NEC_var(_ds=_ds, var=\"B_NEC\", clim=(-50000, 50000), cmap=nio_colormap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad6012-723d-4e04-8f7e-4ac680b0dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B_NEC_res_CHAOS-full: The effect of removing the full CHAOS model, comprising core, magnetosphere, and lithosphere. i.e. mostly space weather signals remaining\")\n",
    "plot_NEC_var(_ds, \"B_NEC_res_CHAOS-full\", clim=(-50, 50), cmap=nio_colormap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc77f9-8a15-4949-b318-ff4a17473843",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"As above, but in QDLat / MLT coordinates\")\n",
    "plot_NEC_var(_ds, \"B_NEC_res_CHAOS-full\", qdmlt=True, clim=(-50, 50), cmap=nio_colormap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfb508-4aed-4a07-b2bc-bcf09763687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks to use for data subselection\n",
    "# There are still a few outliers remaining in the data\n",
    "#   -detect where the residual is anomalously large:\n",
    "outliers = np.fabs((_ds[\"B_NEC_res_CHAOS-full\"]**2).sum(axis=1)) > 2000**2\n",
    "nightside = ~outliers & (_ds[\"SunZenithAngle\"] > 100)\n",
    "nightside_quiet = nightside & (_ds[\"Kp\"] < 3)\n",
    "nightside_quiet_low_MEF = nightside_quiet & (_ds[\"IMF_Em\"] < 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fa342-1f4d-4b38-bc9b-b0d8c2f8302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_stdvs(_ds, ax, title):\n",
    "    (\n",
    "        _ds\n",
    "       .groupby_bins(\"QDLat\", 90)\n",
    "       .std()[\"B_NEC_res_CHAOS-full\"]\n",
    "       .plot.line(x=\"QDLat_bins\", ax=ax)\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, figsize=(20, 5), sharey=True, sharex=True)\n",
    "_plot_stdvs(_ds.where(~outliers), axes[0], \"Without data selection\")\n",
    "_plot_stdvs(_ds.where(nightside), axes[1], \"Night\")\n",
    "_plot_stdvs(_ds.where(nightside_quiet), axes[2], \"Night; Kp<3\")\n",
    "_plot_stdvs(_ds.where(nightside_quiet_low_MEF), axes[3], \"Night; Kp<3; $E_m$<0.8\")\n",
    "axes[0].set_ylim((0, 150))\n",
    "axes[0].set_ylabel(\"B_NEC_res, standard deviations [nT]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f8a68-be41-45f6-9112-250fe9545fd7",
   "metadata": {},
   "source": [
    "Above: the spread of residuals found under increasingly stringent data selection; i.e. why we typically use geomagnetically quiet nightside data for internal field modelling. For a deeper dive on this, see https://swarm.magneticearth.org/notebooks/04a1_geomag-models-vires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf356cc3-9488-48be-a666-dcaa97aadfae",
   "metadata": {},
   "source": [
    "### Begin exploring relationships between parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b54ded-1357-4640-bfe0-8ec518945282",
   "metadata": {},
   "outputs": [],
   "source": [
    "north_auroral_oval = (_ds[\"QDLat\"] > 60) & (_ds[\"QDLat\"] < 80)\n",
    "(\n",
    "    _ds.where(north_auroral_oval & ~outliers, drop=True)\n",
    "    .drop(\"Timestamp\")\n",
    "    .sel(NEC=\"C\")\n",
    "    .plot.scatter(\n",
    "        x=\"IMF_Em\", y=\"B_NEC_res_CHAOS-full\", s=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb52eaf-495d-4e0f-a7e9-964bf372d28c",
   "metadata": {},
   "source": [
    "It is possible to find correlations between the residuals and solar wind parameters such as merging electric field (`IMF_Em` in the datacube; sometimes referred to as $E_m$). This needs to be explored also as a function of position within QDLat / MLT. See Figure 8.1 (page 135) in my thesis (https://doi.org/10.5281/zenodo.3952719)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78db3a8-b0d8-4fe6-84b3-d7b4e42eeb6d",
   "metadata": {},
   "source": [
    "### Temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97933b2e-a8d5-4b80-9067-13981939b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds[\"Altitude\"] = (_ds[\"Radius\"] - REFRAD)/1e3\n",
    "_ds[\"Altitude\"].attrs = {\"units\": \"km\"}\n",
    "_ds[\"Altitude\"].plot.line(x=\"Timestamp\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geomagcubes]",
   "language": "python",
   "name": "conda-env-geomagcubes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
