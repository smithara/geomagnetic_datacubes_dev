{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a403767-f206-4164-8a78-b5e7d31ea71c",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12438d-7927-46d5-9f33-cd99a2598faf",
   "metadata": {},
   "source": [
    "> this notebook made with help from Sam Fielding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934aecd4-84aa-45ff-945c-a739ae274f1a",
   "metadata": {},
   "source": [
    "A proof of concept of applying clustering analysis to the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba565be-8ef3-46db-9b8c-5bd9817b2dfc",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc76e35-949a-48ed-b10e-c7ee95e73e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import zarr\n",
    "# import holoviews as hv\n",
    "# import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from src.env import ICOS_FILE\n",
    "\n",
    "TMPDIR = os.getcwd()\n",
    "zarr_store = os.path.join(TMPDIR, \"datacube_test.zarr\")\n",
    "print(\"Using:\", zarr_store)\n",
    "\n",
    "xr.set_options(\n",
    "    display_expand_attrs=False,\n",
    "    display_expand_data_vars=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52975f85-4a1e-4781-a5ec-f845ef2cb276",
   "metadata": {},
   "source": [
    "## Initialise data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68343f-2c84-4532-9143-f082e337c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Store this information in the datacube directly\n",
    "# Load the coordinates, stored as \"40962\" within the HDF file.\n",
    "gridcoords = pd.read_hdf(ICOS_FILE, key=\"40962\")\n",
    "# gridcoords[\"Latitude\"] = 90 - gridcoords[\"theta\"]\n",
    "# gridcoords[\"Longitude\"] = np.vectorize(lambda x: x if x <= 180 else x - 360)(gridcoords[\"phi\"])\n",
    "gridcoords[\"QDLat\"] = 90 - gridcoords[\"theta\"]\n",
    "gridcoords[\"MLT\"] = gridcoords[\"phi\"]/15\n",
    "gridcoords = gridcoords.to_xarray()\n",
    "gridcoords = gridcoords.drop_vars([\"theta\", \"phi\"])\n",
    "gridcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ffac5-3303-4e44-9e8a-f12b82578f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    zarr_store, engine=\"zarr\", chunks=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75dd6-7388-49eb-a89d-bd7a2b207304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just pick one year\n",
    "_ds = ds.sel(Timestamp=\"2015\")\n",
    "# .. at 1 minute sampling\n",
    "_ds = _ds.isel(Timestamp=slice(0, -1, 6))\n",
    "# # # Just pick the northern polar region\n",
    "# ds.where(ds[\"QDLat\"] > 50, drop=True)\n",
    "# Isolate to the data we want to work with\n",
    "_ds = _ds[[\"B_NEC_res_CHAOS-full\", \"gridpoint_qdmlt\"]]\n",
    "_ds.load()\n",
    "_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e933c-4205-4225-8079-d2eec71349a4",
   "metadata": {},
   "source": [
    "## Extract data to input to KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7861b-03ce-4ffe-ba89-50cb38b3f0df",
   "metadata": {},
   "source": [
    "This next step seems unnecessarily slow. Should find a more sensible way to do it ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7936bae-c984-4228-b4db-57c2e002a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_values_gridwise(ds=_ds, n=20):\n",
    "    # Initialise array to populate with B_NEC vectors\n",
    "    arr = np.full((40962, n*3), np.nan)\n",
    "    # Set fixed seed for predictability\n",
    "    np.random.seed(123)\n",
    "    # Loop through each gridpoint\n",
    "    for grid_index in tqdm(range(40962)):\n",
    "        # Identify data within this gridpoint\n",
    "        B_NEC = ds[\"B_NEC_res_CHAOS-full\"].where(ds[\"gridpoint_qdmlt\"] == grid_index, drop=True).data\n",
    "        # Pick n random entries from given gridpoint\n",
    "        try:\n",
    "            random_choice = np.random.choice(len(B_NEC), size=n, replace=False)\n",
    "        except ValueError:\n",
    "            # There will be nans in the output where there are < n samples available\n",
    "            continue\n",
    "        arr[grid_index, :] = B_NEC[random_choice].flatten()\n",
    "    return arr\n",
    "\n",
    "arr = extract_n_values_gridwise(_ds, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649c29d-aafc-409a-9ed7-3f2cb1b4ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = gridcoords.assign(input_data=((\"index\", \"dim_1\"), arr))\n",
    "cluster_data = cluster_data.dropna(\"index\")\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05401e41-1d15-4f74-ada5-efe75172c548",
   "metadata": {},
   "source": [
    "## Apply KMeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d0ed7-8a2b-4aeb-979d-b3d937ed1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_for_n_clusters(arr, nmax=15):\n",
    "    \"\"\"Perform clustering analysis for n=1,2,3... clusters\n",
    "\n",
    "    Returns a figure showing the variance as a function of\n",
    "    number of clusters\n",
    "    \"\"\"\n",
    "    # Collect variance for each fit\n",
    "    cluster_number = []\n",
    "    variance = []\n",
    "    # Calculate for number of clusters, numbers from 1 to 15\n",
    "    for k in tqdm(range(1, nmax)):\n",
    "        kmeans = KMeans(init=\"random\", n_clusters=k, n_init=30).fit(arr)\n",
    "        variance.append(kmeans.inertia_)\n",
    "        cluster_number.append(k)\n",
    "    # Plot Cluster number against variance\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(cluster_number, variance)\n",
    "    ax.set_xlabel(\"Cluster Number\")\n",
    "    ax.set_ylabel(\"Variance\")\n",
    "    ax.set_title(\"Variance by increasing cluster number\")\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "variance_for_n_clusters(cluster_data[\"input_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7da4f-9ecc-4fdf-984b-a9bcc8faf8d3",
   "metadata": {},
   "source": [
    "Let's pick 5 clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d25808-4a69-4046-8040-ad3ed3244309",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init=\"random\", n_clusters=5, n_init=30).fit(cluster_data[\"input_data\"])\n",
    "clusters = kmeans.predict(cluster_data[\"input_data\"])\n",
    "cluster_data = cluster_data.assign(cluster=((\"index\", clusters)))\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2ab2a-d590-4e8a-93c6-121a585735df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data.plot.scatter(x=\"MLT\", y=\"QDLat\", hue=\"cluster\", s=0.5, cmap=plt.get_cmap(\"turbo\"));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geomagcubes]",
   "language": "python",
   "name": "conda-env-geomagcubes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
